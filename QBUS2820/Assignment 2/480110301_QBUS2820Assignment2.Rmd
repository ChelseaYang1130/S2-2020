---
title: "QBUS2820 Assignment2"
author: "SID: 480110301"

# Abstract
#abstract: |
# Paper size for the document, values of letter and a4
papersize: letter

# Font size of the document, values of 9pt (default), 10pt, 11pt and 12pt
fontsize: 12pt

# Optional: Force one-column layout, default is two-column
one_column: true

# Optional: Enables lineo mode, but only if one_column mode is also true
#lineno: true

# Optional: Enable one-sided layout, default is two-sided
#one_sided: true

# Optional: Specify the depth of section number, default is 5
secnumdepth: 3

# Optional: include-after
#include-after: somefile.tex

# Optional: Skip inserting final break between acknowledgements, default is false
skip_final_break: true

# Optional: Bibliography 
bibliography: pinp

# Customize footer, eg by referencing the vignette
footer_contents: "QBUS2820 Assignment 1"

# Produce a pinp document
output: 
  pinp::pinp:
    latex_engine: xelatex

# Required: Vignette metadata for inclusion in a package.
vignette: >
  %\VignetteIndexEntry{YourPackage-vignetteentry}
  %\VignetteKeywords{YourPackage, r, anotherkeyword}
  %\VignettePackage{YourPackage}
  %\VignetteEngine{knitr::rmarkdown}
  
header-includes: 
   \usepackage{wrapfig,subcaption,array,tabularx,multirow,caption} 
   \usepackage[utf8]{inputenc} 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
message = FALSE
warning = FALSE
```

# Introduction

In a traditional manner, sale prices of houses were predicted by comparing sale prices and costs in the real estate market. There was no general standard to estimate the value of houses. Machine learning techniques therefore play an important role to help establishing models for sale prices of house predictions. As mentioned by Calhoun, the availability of a house price prediction model helps fill up an essential information gap and improve the efficiency of the real estate market (Calhoun, 2003).

This project aims to develop predictive models for sale prices of house with machine learning techniques. With the sale price which is a numerical variable being the response of predictive models, six models are developed and validated.

By comparing the root mean squared errors of predictions, the lasso regression model and random forest model are found to have the best predictive performance for the housing data, compared to elastic net, ridge regression, k-nearest neighbour regression and stepwise regressioin with forward selection. 

# Data processing and exploratory data analysis

There are 36 numeric variables and 43 categorical variables in the housing data

# Feature engineering

\begin{wrapfigure}{r}{0.5\textwidth}
\includegraphics[width=1\linewidth]{miss_plot.png}
\centering
\caption{Visualizing missingness of housing data.}
\label{fig:miss}
\end{wrapfigure}

As shown in Figure \ref{fig:miss}, there are huge amounts of missing values in several columns: 'Alley', 'Fireplace Qu', 'Pool QC', 'Fence', 'Misc Feature'. By calculating the number of null values, these 5 columns are found to have more than 40% missing values within each column. With this issue, such variables are uninformative to ba a feature of predictive models as too few observations are provided. Removing all rows with missing values can lead to significant loss of data while imputation is not appropriate for such largely incomplete columns. Therefore, 'Alley', 'Pool QC', 'Fence', 'Misc Feature' are abandoned.

Besides, there are 19 columns containing missing value but the percentages of missing values are less than 20%. This can be dealed with by imputation. The missing values are imputed by using the most frequent value of each columns.

To deal with outliers of numeric features, standardisation is performed by subtracting the mean, followed by dividing the standard deviation of the corresponding columns. 

After feature engineering, there are 74 informative features, with 36 features being numerical and 38 features being categorical. There are 1570 in the training set while 1210 observations remain  in the testing set. In order to involve categorical features in regression models, dummy variables are created for each categorical feature.

# Methodology

# Validation set

# Conclusion